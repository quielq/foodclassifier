{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f9853e-75c6-4d97-a59c-feee67fe3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['PROJECT_DATA/FOOD-DATA-GROUP1.csv', 'PROJECT_DATA/FOOD-DATA-GROUP3.csv', 'PROJECT_DATA/FOOD-DATA-GROUP2.csv', 'PROJECT_DATA/FOOD-DATA-GROUP5.csv', 'PROJECT_DATA/FOOD-DATA-GROUP4.csv']\n",
      "\n",
      "\n",
      "Total rows before cleaning: 2395\n",
      "Total rows after cleaning: 2395\n",
      "   Unnamed: 0.1  Unnamed: 0                              food  Caloric Value  \\\n",
      "0             0           0                      cream cheese             51   \n",
      "1             1           1                 neufchatel cheese            215   \n",
      "2             2           2  requeijao cremoso light catupiry             49   \n",
      "3             3           3                    ricotta cheese             30   \n",
      "4             4           4              cream cheese low fat             30   \n",
      "\n",
      "    Fat  Saturated Fats  Monounsaturated Fats  Polyunsaturated Fats  \\\n",
      "0   5.0             2.9                   1.3                 0.200   \n",
      "1  19.4            10.9                   4.9                 0.800   \n",
      "2   3.6             2.3                   0.9                 0.000   \n",
      "3   2.0             1.3                   0.5                 0.002   \n",
      "4   2.3             1.4                   0.6                 0.042   \n",
      "\n",
      "   Carbohydrates  Sugars  ...  Calcium  Copper   Iron  Magnesium  Manganese  \\\n",
      "0            0.8   0.500  ...    0.008  14.100  0.082      0.027      1.300   \n",
      "1            3.1   2.700  ...   99.500   0.034  0.100      8.500      0.088   \n",
      "2            0.9   3.400  ...    0.000   0.000  0.000      0.000      0.000   \n",
      "3            1.5   0.091  ...    0.097  41.200  0.097      0.096      4.000   \n",
      "4            1.2   0.900  ...   22.200   0.072  0.008      1.200      0.098   \n",
      "\n",
      "   Phosphorus  Potassium  Selenium   Zinc  Nutrition Density  \n",
      "0       0.091       15.5    19.100  0.039              7.070  \n",
      "1     117.300      129.2     0.054  0.700            130.100  \n",
      "2       0.000        0.0     0.000  0.000              5.400  \n",
      "3       0.024       30.8    43.800  0.035              5.196  \n",
      "4      22.800       37.1     0.034  0.053             27.007  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "#MiniProject Code - Naive Bayes\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Setup of dataset path\n",
    "base_folder = os.path.join(\"PROJECT_DATA/\")\n",
    "csv_pattern = os.path.join(base_folder, \"FOOD-DATA-GROUP*.csv\")\n",
    "\n",
    "#Features to be used, same with what was written for AdaBoost\n",
    "\n",
    "feature_cols = [\n",
    "    \"Protein\", \"Fat\", \"Carbohydrates\", \"Caloric Value\",\n",
    "    \"Sugars\", \"Dietary Fiber\", \"Saturated Fats\",\n",
    "    \"Monounsaturated Fats\", \"Polyunsaturated Fats\",\n",
    "    \"Sodium\", \"Potassium\"\n",
    "]\n",
    "\n",
    "#Loading of dataset\n",
    "csv_files = glob.glob(csv_pattern)\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "#Loading of files and combining \n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    df_temp = pd.read_csv(file)\n",
    "    dataframes.append(df_temp)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(\"\\n\\nTotal rows before cleaning:\", len(df))\n",
    "\n",
    "#Cleaning by dropping rows with missing values\n",
    "df = df.dropna(subset=feature_cols)\n",
    "print(\"Total rows after cleaning:\", len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4718c896-b883-4416-b8c6-2ef761f5c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Weight Loss    1016\n",
      "Muscle Gain     649\n",
      "Endurance       386\n",
      "No Category     344\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assignment of Labels\n",
    "\n",
    "def assign_label(row):\n",
    "    \"\"\"\n",
    "    Assignment of labels using the following criteria:\n",
    "    Muscle Gain if Protein >=15 OR (Protein >=10 AND Caloric Value >= 200)\n",
    "    Endurance if Carbohydrates >= 30 OR Sugars >= 12 OR (Carbohydrates >=20 AND Sodium >= 140)\n",
    "    Weight Loss if Caloric Value < 150 AND Fat < 5 AND (Carbohydrates < 20 OR Dietary Fiber >= 3)\n",
    "    \n",
    "    Assignment of labels will be done in that order of priority.\n",
    "    \"\"\"\n",
    "\n",
    "    #MUSCLE GAIN\n",
    "    muscle_gain = (\n",
    "        (row[\"Protein\"] >= 15) or\n",
    "        (row[\"Protein\"] >= 10 and row[\"Caloric Value\"] >= 200)\n",
    "    )\n",
    "\n",
    "    #ENDURANCE\n",
    "    endurance = (\n",
    "        (row[\"Carbohydrates\"] >= 30) or\n",
    "        (row[\"Sugars\"] >= 12) or\n",
    "        (row[\"Carbohydrates\"] >= 20 and row[\"Sodium\"] >= 140)\n",
    "    )\n",
    "\n",
    "    #WEIGHT LOSS\n",
    "    weight_loss = (\n",
    "        (row[\"Caloric Value\"] < 150) and\n",
    "        (row[\"Fat\"] < 5) and\n",
    "        ((row[\"Carbohydrates\"] < 20) or (row[\"Dietary Fiber\"] >=3))\n",
    "    )\n",
    "\n",
    "    #ASSIGNMENT BASED ON PRIORITY\n",
    "    if muscle_gain:\n",
    "        return \"Muscle Gain\"\n",
    "    if endurance:\n",
    "        return \"Endurance\"\n",
    "    if weight_loss:\n",
    "        return \"Weight Loss\"\n",
    "    return \"No Category\"\n",
    "\n",
    "#Tagging of labels\n",
    "df[\"Label\"] = df.apply(assign_label, axis=1)\n",
    "label_counts = df[\"Label\"].value_counts()\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a502080b-c98d-432f-bfe2-5aa29e6c7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "def run_naive_bayes(df, feature_cols):\n",
    "    \"\"\"\n",
    "    This is the function to run the Gaussian Naive Bayes\n",
    "    \"\"\"\n",
    "    \n",
    "    #Dropping the No Category rows\n",
    "    df_model = df[df[\"Label\"] != \"No Category\"].copy()\n",
    "    # df_model = df.copy() Tried to include \"No Category\" but got lower results\n",
    "    X = df_model[feature_cols].values\n",
    "    y = df_model[\"Label\"].values\n",
    "    \n",
    "    #Cross-Validation\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    #Setting of Gaussian Naive Bayes as the NB Algorithm to be used\n",
    "    nb_model = GaussianNB()\n",
    "    \n",
    "\n",
    "    \n",
    "    #METRICS\n",
    "    cv_recall = cross_val_score(nb_model, X, y, cv = 5, scoring = 'recall_macro')\n",
    "    cv_precision = cross_val_score(nb_model, X, y, cv = 5, scoring = 'precision_macro')\n",
    "    cv_f1 = cross_val_score(nb_model, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    cv_accuracy = cross_val_score(nb_model, X, y, cv=5, scoring = 'accuracy')\n",
    "    \n",
    "    print(\"\\n\\n===== GAUSSIAN NAIVE BAYES RESULTS =====\")\n",
    "    #For checking only\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Example row from X:\", X[0])\n",
    "    print(\"Length of y:\", len(y))\n",
    "    print(\"Unique Labels:\", set(y))\n",
    "    print(\"\\n\")\n",
    "    print(df_model[\"Label\"].value_counts())\n",
    "    print(\"\\nMETRICS\")\n",
    "    print(\"Accuracy scores:\", cv_accuracy)\n",
    "    print(\"Average Accuracy:\", cv_accuracy.mean())\n",
    "    print(\"\\nRecall scores:\", cv_recall)\n",
    "    print(\"Average Recall:\", cv_recall.mean())\n",
    "    print(\"\\nPrecision scores:\", cv_precision)\n",
    "    print(\"Average Precision:\", cv_precision.mean())\n",
    "    print(\"\\nF1 scores:\", cv_f1)\n",
    "    print(\"Average F1:\", cv_f1.mean())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": cv_accuracy.mean(),\n",
    "        \"precision\": cv_precision.mean(),\n",
    "        \"recall\": cv_recall.mean(),\n",
    "        \"f1\": cv_f1.mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9998d140-7f3a-4dbf-95b1-d8b3b92e235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "def run_svm_rbf(df, feature_cols):\n",
    "    \"\"\"\n",
    "    This is runs the SVM (RBF Kernel) algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    #Same setup of removing the 'No Category' wors\n",
    "    df_model = df[df[\"Label\"] != \"No Category\"].copy()\n",
    "\n",
    "    X = df_model[feature_cols].values\n",
    "    y = df_model[\"Label\"].values\n",
    "    \n",
    "    #Importing of libraries for SVM\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.preprocessing import StandardScaler #needed since the features aren't of the same scale\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "    #SVM Pipeline -- scaling and classifier\n",
    "    svm_model = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", random_state=42))\n",
    "    ])\n",
    "\n",
    "    #Grid Search\n",
    "    param_grid = {\n",
    "        \"svc__C\": [0.1, 1, 10],\n",
    "        \"svc__gamma\": [0.01, 0.1, 1]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=svm_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"f1_macro\", #This is the one being optimized\n",
    "        cv=5 #5-fold cross-validation\n",
    "    )\n",
    "\n",
    "    print(\"\\nRunning GridSearchCV for SVM...\")\n",
    "    grid_search.fit(X,y)\n",
    "    print(\"\\n===== SVM (RBF) GRID SEARCH RESULTS =====\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best CV F1-macro from GridSearch:\", grid_search.best_score_)\n",
    "\n",
    "    #Using the best Model from GridSearchCV\n",
    "    best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "    #METRICS\n",
    "    cv_recall = cross_val_score(best_svm_model, X, y, cv = 5, scoring = 'recall_macro')\n",
    "    cv_precision = cross_val_score(best_svm_model, X, y, cv = 5, scoring = 'precision_macro')\n",
    "    cv_f1 = cross_val_score(best_svm_model, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    cv_accuracy = cross_val_score(best_svm_model, X, y, cv=5, scoring = 'accuracy')\n",
    "\n",
    "    print(\"\\n\\n===== SVM (RBF) RESULTS =====\")\n",
    "     #For checking only\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Example row from X:\", X[0])\n",
    "    print(\"Length of y:\", len(y))\n",
    "    print(\"Unique Labels:\", set(y))\n",
    "    print(\"\\n\")\n",
    "    print(df_model[\"Label\"].value_counts())\n",
    "    print(\"\\nMETRICS\")\n",
    "    print(\"Accuracy scores:\", cv_accuracy)\n",
    "    print(\"Average Accuracy:\", cv_accuracy.mean())\n",
    "    print(\"\\nRecall scores:\", cv_recall)\n",
    "    print(\"Average Recall:\", cv_recall.mean())\n",
    "    print(\"\\nPrecision scores:\", cv_precision)\n",
    "    print(\"Average Precision:\", cv_precision.mean())\n",
    "    print(\"\\nF1 scores:\", cv_f1)\n",
    "    print(\"Average F1:\", cv_f1.mean())\n",
    "\n",
    "    return {\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"gridsearch_best_f1\": grid_search.best_score_,\n",
    "        \"accuracy\": cv_accuracy.mean(),\n",
    "        \"precision\": cv_precision.mean(),\n",
    "        \"recall\": cv_recall.mean(),\n",
    "        \"f1\": cv_f1.mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706c4730-970c-4487-9055-95af1c23c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== GAUSSIAN NAIVE BAYES RESULTS =====\n",
      "Shape of X: (2051, 11)\n",
      "Example row from X: [ 0.8  3.6  0.9 49.   3.4  0.1  2.3  0.9  0.   0.   0. ]\n",
      "Length of y: 2051\n",
      "Unique Labels: {'Weight Loss', 'Endurance', 'Muscle Gain'}\n",
      "\n",
      "\n",
      "Label\n",
      "Weight Loss    1016\n",
      "Muscle Gain     649\n",
      "Endurance       386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "METRICS\n",
      "Accuracy scores: [0.87347932 0.89756098 0.90243902 0.93170732 0.85365854]\n",
      "Average Accuracy: 0.891769034478666\n",
      "\n",
      "Recall scores: [0.86425632 0.87421199 0.89791128 0.91885471 0.85292524]\n",
      "Average Recall: 0.8816319079864531\n",
      "\n",
      "Precision scores: [0.85371738 0.86673314 0.87667136 0.91885471 0.83497036]\n",
      "Average Precision: 0.8701893903106768\n",
      "\n",
      "F1 scores: [0.84385223 0.87018346 0.88229028 0.91885471 0.82622815]\n",
      "Average F1: 0.8682817646374117\n",
      "\n",
      "Running GridSearchCV for SVM...\n",
      "\n",
      "===== SVM (RBF) GRID SEARCH RESULTS =====\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.01}\n",
      "Best CV F1-macro from GridSearch: 0.9205782940156929\n",
      "\n",
      "\n",
      "===== SVM (RBF) RESULTS =====\n",
      "Shape of X: (2051, 11)\n",
      "Example row from X: [ 0.8  3.6  0.9 49.   3.4  0.1  2.3  0.9  0.   0.   0. ]\n",
      "Length of y: 2051\n",
      "Unique Labels: {'Weight Loss', 'Endurance', 'Muscle Gain'}\n",
      "\n",
      "\n",
      "Label\n",
      "Weight Loss    1016\n",
      "Muscle Gain     649\n",
      "Endurance       386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "METRICS\n",
      "Accuracy scores: [0.97323601 0.93658537 0.96829268 0.96829268 0.84878049]\n",
      "Average Accuracy: 0.9390374458489111\n",
      "\n",
      "Recall scores: [0.96576812 0.89450549 0.96329533 0.95086178 0.8411841 ]\n",
      "Average Recall: 0.923122965005601\n",
      "\n",
      "Precision scores: [0.9658706  0.94476852 0.95807034 0.97000324 0.84806845]\n",
      "Average Precision: 0.9373562293924597\n",
      "\n",
      "F1 scores: [0.96562514 0.91060457 0.9605482  0.95942307 0.80669049]\n",
      "Average F1: 0.9205782940156929\n"
     ]
    }
   ],
   "source": [
    "#CALLING OF THE FUNCTIONS\n",
    "\n",
    "nb_results = run_naive_bayes(df,feature_cols)\n",
    "svm_results = run_svm_rbf(df, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e722727-711f-4753-b4ef-beb5077c41b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ANOVA RESULTS ======\n",
      "                 Feature     F_score        p_value\n",
      "29            Phosphorus  425.669193  2.557360e-155\n",
      "7                Protein  402.304507  4.303354e-148\n",
      "0          Caloric Value  395.085269  7.770699e-146\n",
      "5          Carbohydrates  311.226861  9.522996e-119\n",
      "30             Potassium  282.221456  5.571074e-109\n",
      "33     Nutrition Density  253.123871   5.814877e-99\n",
      "27             Magnesium  248.170315   3.110370e-97\n",
      "6                 Sugars  244.574352   5.644779e-96\n",
      "17            Vitamin B3  234.010470   2.954457e-92\n",
      "1                    Fat  184.535626   2.058123e-74\n",
      "2         Saturated Fats  154.510566   3.174472e-63\n",
      "32                  Zinc  151.126335   6.033472e-62\n",
      "24               Calcium  147.349741   1.629640e-60\n",
      "19            Vitamin B6  137.506519   9.225385e-57\n",
      "26                  Iron  135.623675   4.858169e-56\n",
      "3   Monounsaturated Fats  120.809898   2.536172e-50\n",
      "18            Vitamin B5  103.628755   1.345941e-43\n",
      "11                 Water  102.917011   2.569297e-43\n",
      "4   Polyunsaturated Fats   85.754993   1.716317e-36\n",
      "9            Cholesterol   54.319617   1.032071e-23\n",
      "13            Vitamin B1   51.898696   1.031006e-22\n",
      "8          Dietary Fiber   50.565700   3.669361e-22\n",
      "22             Vitamin E   48.282345   3.240263e-21\n",
      "16            Vitamin B2   37.771875   7.783755e-17\n",
      "10                Sodium   16.547777   7.427475e-08\n",
      "21             Vitamin D   13.268584   1.881661e-06\n",
      "28             Manganese   13.200971   2.011551e-06\n",
      "31              Selenium    7.387843   6.353590e-04\n",
      "25                Copper    4.470212   1.155678e-02\n",
      "14           Vitamin B11    1.067585   3.440291e-01\n",
      "20             Vitamin C    0.874243   4.173332e-01\n",
      "12             Vitamin A    0.712280   4.906462e-01\n",
      "23             Vitamin K    0.339895   7.118854e-01\n",
      "15           Vitamin B12    0.311460   7.324113e-01\n",
      "\n",
      "Significant features (p <0.05):\n",
      "['Phosphorus', 'Protein', 'Caloric Value', 'Carbohydrates', 'Potassium', 'Nutrition Density', 'Magnesium', 'Sugars', 'Vitamin B3', 'Fat', 'Saturated Fats', 'Zinc', 'Calcium', 'Vitamin B6', 'Iron', 'Monounsaturated Fats', 'Vitamin B5', 'Water', 'Polyunsaturated Fats', 'Cholesterol', 'Vitamin B1', 'Dietary Fiber', 'Vitamin E', 'Vitamin B2', 'Sodium', 'Vitamin D', 'Manganese', 'Selenium', 'Copper']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNo significant features found. Using all features instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#CORRELATION HEATMAPS PER CLASS\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m \u001b[38;5;66;03m#Data Visualization Library\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     60\u001b[0m features_to_plot \u001b[38;5;241m=\u001b[39m significant_features\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#FEATURE IMPORTANCE\n",
    "#In our paper, we declared that \"On the other hand, the macronutrient trends of food within each fitness label \n",
    "#will be determined by identifying feature importance using logistic regression.\"\n",
    "#But in this section, we will also also do ANOVA, Correlation Heatmaps, Mean Profiles, and Logistic Regression\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Including all features for analysis\n",
    "all_features = [\n",
    "    \"Caloric Value\", \"Fat\", \"Saturated Fats\", \"Monounsaturated Fats\", \"Polyunsaturated Fats\",\n",
    "    \"Carbohydrates\", \"Sugars\", \"Protein\", \"Dietary Fiber\", \"Cholesterol\",\n",
    "    \"Sodium\", \"Water\",\n",
    "    \"Vitamin A\", \"Vitamin B1\", \"Vitamin B11\", \"Vitamin B12\", \"Vitamin B2\",\n",
    "    \"Vitamin B3\", \"Vitamin B5\", \"Vitamin B6\", \"Vitamin C\", \"Vitamin D\",\n",
    "    \"Vitamin E\", \"Vitamin K\",\n",
    "    \"Calcium\", \"Copper\", \"Iron\", \"Magnesium\", \"Manganese\",\n",
    "    \"Phosphorus\", \"Potassium\", \"Selenium\", \"Zinc\",\n",
    "    \"Nutrition Density\"\n",
    "]\n",
    "\n",
    "#Excluded \"No Category\" in the analysis\n",
    "df_stats = df[df[\"Label\"] != \"No Category\"].copy()\n",
    "df_stats = df_stats.dropna(subset=all_features)\n",
    "\n",
    "#ANOVA\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X_stats = df_stats[all_features].values\n",
    "y_stats = df_stats[\"Label\"].values\n",
    "\n",
    "F_scores, p_values = f_classif(X_stats, y_stats)\n",
    "anova_results = pd.DataFrame({\n",
    "    \"Feature\": all_features,\n",
    "    \"F_score\": F_scores,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "anova_results_sorted = anova_results.sort_values(\"F_score\", ascending=False)\n",
    "\n",
    "print(\"====== ANOVA RESULTS ======\")\n",
    "print(anova_results_sorted)\n",
    "\n",
    "#Statistically significant features\n",
    "alpha=0.05\n",
    "significant_features = anova_results_sorted[anova_results_sorted[\"p_value\"] < alpha][\"Feature\"].tolist()\n",
    "\n",
    "print(\"\\nSignificant features (p <0.05):\")\n",
    "print(significant_features)\n",
    "\n",
    "#If no significant features, use all\n",
    "if len(significant_features) == 0:\n",
    "    significant_features = feature_cols.copy()\n",
    "    print(\"\\nNo significant features found. Using all features instead.\")\n",
    "\n",
    "\n",
    "#CORRELATION HEATMAPS PER CLASS\n",
    "import seaborn as sns #Data Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features_to_plot = significant_features\n",
    "\n",
    "for label in sorted(df_stats[\"Label\"].unique()):\n",
    "    subset = df_stats[df_stats[\"Label\"] == label][features_to_plot]\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(\n",
    "        subset.corr(),\n",
    "        cmap=\"coolwarm\",\n",
    "        annot=False\n",
    "    )\n",
    "    plt.title(f\"Correlation Heatmap - {label}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#MEAN NUTRIENT PROFILES (ONLY SIGNIFICANT FEATURES)\n",
    "mean_table = df_stats.groupby(\"Label\")[features_to_plot].mean()\n",
    "print(\"===== MEAN NUTRIENT VALUES (SIGNIFICANT FEATURES ONLY) =====\")\n",
    "print(mean_table)\n",
    "\n",
    "#LOGISTIC REGRESSION FEATURE IMPORTANCE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_lr = df_stats[all_features].values\n",
    "y_lr = df_stats[\"Label\"].values\n",
    "\n",
    "#Scale Features\n",
    "scaler_lr = StandardScaler()\n",
    "X_lr_scaled = scaler_lr.fit_transform(X_lr)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    multi_class = \"multinomial\",\n",
    "    max_iter = 500,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "logreg.fit(X_lr_scaled, y_lr)\n",
    "\n",
    "coef_table = pd.DataFrame(\n",
    "    logreg.coef_,\n",
    "    columns = all_features,\n",
    "    index = logreg.classes_\n",
    ")\n",
    "\n",
    "print(\"\\n===== LOGISTIC REGRESSION COEFFICIENTS (ALL FEATURES) ======\")\n",
    "print(coef_table)\n",
    "\n",
    "#Only Significant Features\n",
    "coef_sig = coef_table[significant_features]\n",
    "print(\"\\n===== LOGISTIC REGRESSION COEFFICIENTS (SIGNIFICANT FEATURES ONLY) ======\")\n",
    "print(coef_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a328bcd-6999-4136-b3a6-440fdc9400d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
